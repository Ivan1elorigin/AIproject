{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b375ab7-13e1-4f60-899e-466ae9a3ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "import cupy as np # en vez de usar numpy usamos cupy para tirar de grÃ¡fica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f7e682b-1bcc-417f-b2ae-cf12d6e40acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.cuda.runtime.getDeviceCount())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f225f0-9b7e-4e00-a453-eef56bb57278",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cudf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcudf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m cudf\u001b[38;5;241m.\u001b[39mDataFrame(data)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cudf'"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "df = cudf.DataFrame(data)  # En lugar de `pd.DataFrame(data)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d744c139-a10a-4961-bae7-d2bf74e4ce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c86e00c-82d5-4405-9dc0-292d6042607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:03:56) [MSC v.1929 64 bit (AMD64)]\n",
      "NLTK: 3.8.1\n",
      "Scikit-learn: 1.4.2\n",
      "Pandas: 2.2.2\n",
      "NumPy: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "print('Python: {}'.format(sys.version))\n",
    "print('NLTK: {}'.format(nltk.__version__))\n",
    "print('Scikit-learn: {}'.format(sklearn.__version__))\n",
    "print('Pandas: {}'.format(pd.__version__))\n",
    "print('NumPy: {}'.format(np.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfdfe766-ee88-4287-b4b3-44bf020e6654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('labeled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47adf1a2-0a44-4f7f-a9f9-1447323a1718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e782099a-d181-47a9-9aa4-00b06671178b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither',\n",
       "       'class', 'tweet'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "596fac56-cad7-485d-928a-1a9b4dfb5fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither'] ,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "485961fc-7b2a-4482-8877-ff7dec1009ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80812846-af56-4b7b-8c5a-c8280298e213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cd8fa65-7987-4453-972a-8bb17d62adc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   class   24783 non-null  int64 \n",
      " 1   tweet   24783 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 387.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7105e22-d969-4561-9056-1a8a7e973c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa526146-3159-4402-b487-5f15b2c7530a",
   "metadata": {},
   "source": [
    "<strong>class:</strong> class label for majority of CF users. 0 - hate speech 1 - offensive language 2 - neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5522f78a-8e90-477b-a848-f43c31707e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[\"tweet\"]\n",
    "text[:10]\n",
    "\n",
    "label = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99f75a8c-701a-4b99-9d0f-b9d79ba999b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar '!!!' al inicio. Eliminar 'RT'. Sustituir nombres de usuario\n",
    "# text = text.str.replace(r'^!+', '', regex=True).str.replace(r'^RT\\s+', '', regex=True).str.replace(r'@\\w+', 'users_name', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1476f292-f7a7-46ae-b20a-b62c98785115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar '!!!' al inicio. Eliminar 'RT' correctamente. Sustituir nombres de usuario. Eliminar espacios en blanco sobrantes\n",
    "# processed = text.str.replace(r'^!+', '', regex=True).str.replace(r'^RT\\s+', '', regex=True).str.replace(r'@\\w+', 'users_name', regex=True).str.strip()                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feda239c-5cac-4321-aef1-f8848626ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar '!!!' al inicio. Eliminar 'RT' correctamente en cualquier parte del texto. Sustituir nombres de usuario. Eliminar espacios en blanco sobrantes\n",
    "processed = text .str.replace(r'^!+', '', regex=True).str.replace(r'\\bRT\\b\\s+', '', regex=True).str.replace(r'@\\w+', 'users_name', regex=True).str.strip()                                                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cef3f94-ee20-4dae-bd3c-36a48dde6ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ', regex=True)\n",
    "\n",
    "# Replace whitespace between terms with a single space\n",
    "processed = processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "# Remove leading and trailing whitespace\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eff12867-5c73-46b6-860a-6061edd76090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        users_name  as a woman you shouldn t complain ...\n",
       "1        users_name  boy dats cold   tyga dwn bad for c...\n",
       "2        users_name dawg     users_name  you ever fuck ...\n",
       "3            users_name  users_name she look like a tranny\n",
       "4        users_name  the shit you hear about me might b...\n",
       "                               ...                        \n",
       "24778    you s a muthaf   in lie   8220 users_name  use...\n",
       "24779    you ve gone and broke the wrong heart baby  an...\n",
       "24780    young buck wanna eat     dat nigguh like i ain...\n",
       "24781                youu got wild bitches tellin you lies\n",
       "24782      ruffled   ntac eileen dahlia   beautiful col...\n",
       "Name: tweet, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed = processed.str.lower()\n",
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9322afc9-029c-4acc-8997-3fff0051d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c591e451-f4c4-41a6-9189-39e84257b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(ps.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53922b89-fd3c-47b7-9239-565eb1605231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        users_nam woman complain clean hous amp man al...\n",
       "1        users_nam boy dat cold tyga dwn bad cuffin dat...\n",
       "2        users_nam dawg users_nam ever fuck bitch start...\n",
       "3                     users_nam users_nam look like tranni\n",
       "4        users_nam shit hear might true might faker bit...\n",
       "                               ...                        \n",
       "24778    muthaf lie 8220 users_nam users_nam users_nam ...\n",
       "24779      gone broke wrong heart babi drove redneck crazi\n",
       "24780    young buck wanna eat dat nigguh like aint fuck...\n",
       "24781                       youu got wild bitch tellin lie\n",
       "24782    ruffl ntac eileen dahlia beauti color combin p...\n",
       "Name: tweet, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57d09276-e5eb-4ae2-8826-c7af82d5bd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 19438\n",
      "Most common words: [('users_nam', 19272), ('bitch', 11480), ('hoe', 4352), ('128514', 3241), ('http', 3127), ('co', 3013), ('like', 2873), ('fuck', 2269), ('pussi', 2267), ('nigga', 2019), ('get', 1782), ('8220', 1726), ('8221', 1682), ('got', 1612), ('ass', 1598)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for message in processed:\n",
    "    words = word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "# Print the result\n",
    "print('Number of words: {}'.format(len(all_words)))\n",
    "print('Most common words: {}'.format(all_words.most_common(15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd3a83fa-4ec4-4afd-b0eb-3d29f4679997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the 1500 most common words as features\n",
    "word_features = [x[0] for x in all_words.most_common(1500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb1ef13c-6941-401a-ac64-4998ab21763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05874cc0-cbba-4ad5-86af-d4d9838d8063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users_nam\n",
      "trash\n",
      "amp\n",
      "man\n",
      "take\n",
      "alway\n",
      "hous\n",
      "woman\n",
      "clean\n",
      "complain\n"
     ]
    }
   ],
   "source": [
    "features = find_features(processed[0])\n",
    "for key, value in features.items():\n",
    "    if value == True:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcd146bc-53ec-4f32-855c-ee04c4468cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('users_nam', True),\n",
       " ('bitch', False),\n",
       " ('hoe', False),\n",
       " ('128514', False),\n",
       " ('http', False),\n",
       " ('co', False),\n",
       " ('like', False),\n",
       " ('fuck', False),\n",
       " ('pussi', False),\n",
       " ('nigga', False)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(features.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e8049b4-8aed-41cc-8bf4-d6667534243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = list(zip(processed, label))\n",
    "\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(messages)\n",
    "\n",
    "# Call find_features function for each SMS message\n",
    "feature_set = [(find_features(text), label) for (text, label) in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e27f737c-aa14-4303-94e9-e2fd0751d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, test = train_test_split(feature_set, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "774b53b8-90aa-4fdd-b548-a5a87bfea989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18587\n",
      "6196\n"
     ]
    }
   ],
   "source": [
    "print(len(training))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ee7302-7969-4f4f-a3a0-2a2de59434cc",
   "metadata": {},
   "source": [
    "## Scikit-learn Classifier with NLTK\n",
    "Now, we build the training and test set, we can build machine learning model in scikit-learn. We are using the following alogithms and see the performance of each ones,\n",
    "\n",
    "- KNearestNeighbors\n",
    "\n",
    "- Random Forest\n",
    "- Decision Tree\n",
    "\n",
    "- Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b919b1d4-4bc4-4725-bf06-fb5576e7587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "names = ['K Nearest Neighbors', 'Decision Tree', 'Random Forest', 'Naive Bayes']\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    MultinomialNB()\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c30d277f-ac70-4d9f-951b-3ad2c9842207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x296eded9480>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b6f5961-1db0-4d3c-92f4-a671dcb658e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors model Accuracy: 0.8653970303421562\n",
      "Decision Tree model Accuracy: 0.8710458360232408\n",
      "Random Forest model Accuracy: 0.8999354422207876\n",
      "Naive Bayes model Accuracy: 0.8897675919948353\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(training)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, test)\n",
    "    print(\"{} model Accuracy: {}\".format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed40cec5-656a-4d63-8f62-8ea5dfd36a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier model Accuracy: 0.8917043253712073\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Since VotingClassifier can accept list type of models\n",
    "models = list(zip(names, classifiers))\n",
    "\n",
    "nltk_ensemble = SklearnClassifier(VotingClassifier(estimators=models, voting='hard', n_jobs=-1))\n",
    "nltk_ensemble.train(training)\n",
    "accuracy = nltk.classify.accuracy(nltk_ensemble, test)\n",
    "print(\"Voting Classifier model Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c657a514-f16c-47aa-b6c1-eada0354067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features, labels = zip(*test)\n",
    "prediction = nltk_ensemble.classify_many(text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90ef2fdf-21d8-4775-9119-68ca31510cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.31      0.35       350\n",
      "           1       0.93      0.94      0.94      4847\n",
      "           2       0.83      0.84      0.84       999\n",
      "\n",
      "    accuracy                           0.89      6196\n",
      "   macro avg       0.72      0.70      0.71      6196\n",
      "weighted avg       0.88      0.89      0.89      6196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8d5a06e-7f31-4a7e-84f8-26c92a927f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>neither</th>\n",
       "      <th>ofensive language</th>\n",
       "      <th>hate speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">actual</th>\n",
       "      <th>neither</th>\n",
       "      <td>109</td>\n",
       "      <td>201</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ofensive language</th>\n",
       "      <td>143</td>\n",
       "      <td>4575</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate speech</th>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         predicted                              \n",
       "                           neither ofensive language hate speech\n",
       "actual neither                 109               201          40\n",
       "       ofensive language       143              4575         129\n",
       "       hate speech              13               145         841"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame( confusion_matrix(labels, prediction),\n",
    "             index=[['actual', 'actual', 'actual'], ['neither', 'ofensive language', 'hate speech']],\n",
    "             columns = [['predicted', 'predicted', 'predicted'], ['neither', 'ofensive language', 'hate speech']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7dc90102-e45c-4d3e-8258-7f5858c01bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f4a98a96-0d20-444c-9db3-900c8e2b8c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = {\n",
    "    \"k_nearest_neighbors\": \"knn_model.pkl\",\n",
    "    \"decision_tree\": \"decision_tree_model.pkl\",\n",
    "    \"random_forest\": \"random_forest_model.pkl\",\n",
    "    \"naive_bayes\": \"naive_bayes_model.pkl\",\n",
    "    \"voting_classifier\": \"voting_classifier.pkl\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98e2da17-8cd9-4896-a152-3a243e1b59d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(models, voting_classifier):\n",
    "    for name, model in models:\n",
    "        with open(model_paths[name.lower().replace(\" \", \"_\")], 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    with open(model_paths[\"voting_classifier\"], 'wb') as f:\n",
    "        pickle.dump(voting_classifier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e0129967-614e-4c56-99f0-bd989d1e57d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_save = list(zip(names, classifiers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5abff0fb-f315-497d-835e-69f9fd3fd6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models(models_to_save, nltk_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "35512a44-3eb6-4fe6-81cb-583802367284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para cargar los modelos:\n",
    "model_paths = {\n",
    "    \"k_nearest_neighbors\": \"knn_model.pkl\",\n",
    "    \"decision_tree\": \"decision_tree_model.pkl\",\n",
    "    \"random_forest\": \"random_forest_model.pkl\",\n",
    "    \"naive_bayes\": \"naive_bayes_model.pkl\",\n",
    "    \"voting_classifier\": \"voting_classifier.pkl\"\n",
    "}\n",
    "\n",
    "def load_models():\n",
    "    loaded_models = {}\n",
    "    for name, path in model_paths.items():\n",
    "        with open(path, 'rb') as f:\n",
    "            loaded_models[name] = pickle.load(f)\n",
    "    return loaded_models\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
